{
    "model": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "draft_model": "meta-llama/Llama-3.2-1B-Instruct",
    "offload": true,
    "max_length": 4096,
    "num_cache_layers": 0,
    "generation_length": 256,
    "max_turns": 12,
    "topk": 32,
    "temperature": 0.6,
    "topp": 0.9,
    "repetition_penalty": 1.05,
    "width": 16,
    "num_beams": 24,
    "depth": 16,
    "template": "meta-llama3"
}
